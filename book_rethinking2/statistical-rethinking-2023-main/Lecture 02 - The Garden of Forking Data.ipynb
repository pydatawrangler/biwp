{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60123f05-5e3a-42b2-b948-db9e8d7fc5ee",
   "metadata": {},
   "source": [
    "# [Lecture 02 - The Garden of Forking Data](https://youtu.be/R1vcdhPBlXA?si=rL3BOz9hHxkPt79m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14629f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mModule aliases imported by init_notebook.py:\n",
      "--------------------------------------------\n",
      "\u001b[32mimport\u001b[34m numpy \u001b[32mas\u001b[34m np\n",
      "\n",
      "\u001b[32mimport\u001b[34m pandas \u001b[32mas\u001b[34m pd\n",
      "\n",
      "\u001b[32mimport\u001b[34m statsmodels.formula.api \u001b[32mas\u001b[34m smf\n",
      "\n",
      "\u001b[32mimport\u001b[34m pymc \u001b[32mas\u001b[34m pm\n",
      "\n",
      "\u001b[32mimport\u001b[34m xarray \u001b[32mas\u001b[34m xr\n",
      "\n",
      "\u001b[32mimport\u001b[34m arviz \u001b[32mas\u001b[34m az\n",
      "\n",
      "\u001b[32mimport\u001b[34m utils \u001b[32mas\u001b[34m utils\n",
      "\n",
      "\u001b[32mfrom\u001b[34m scipy \u001b[32mimport\u001b[34m stats \u001b[32mas\u001b[34m stats\n",
      "\n",
      "\u001b[32mfrom\u001b[34m matplotlib \u001b[32mimport\u001b[34m pyplot \u001b[32mas\u001b[34m plt\n",
      "\n",
      "\u001b[31mWatermark:\n",
      "----------\n",
      "\u001b[34mLast updated: 2025-03-29T22:58:56.935990-06:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.11\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 18.1.8 \n",
      "OS          : Darwin\n",
      "Release     : 24.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      "\u001b[34mnumpy      : 1.26.4\n",
      "IPython    : 8.12.3\n",
      "watermark  : 2.5.0\n",
      "statsmodels: 0.14.4\n",
      "matplotlib : 3.10.1\n",
      "pandas     : 2.2.2\n",
      "xarray     : 2025.3.0\n",
      "arviz      : 0.17.0\n",
      "pymc       : 5.18.2\n",
      "scipy      : 1.12.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run init_notebook.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125141e5",
   "metadata": {},
   "source": [
    "# Task: What proportion of earth's surface is covered with water?\n",
    "\n",
    "## Workflow (Drawing the Owl)\n",
    "\n",
    "1. Define **generative model** of tossing the globe\n",
    "2. Define an **estimand** -- in this case, the proportion of globe covered in water\n",
    "3. **Design a statistical procedure** to produce an estimate of the estimand\n",
    "4. **Validate the statistical procedure** (3) using the generative model -- can we recover an accurate estimate of (2) from data generated by (1)\n",
    "5. **Apply statistical procedure** (3) to real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9103a6d",
   "metadata": {},
   "source": [
    "## 1, 2. Define generative model of globe tossing\n",
    "- $p$: proportion of water -- this is the **estimand**, what we'd like to estimate\n",
    "- $N$: number of tosses  -- we control this via experiment\n",
    "- $W$: number of `Water` observations\n",
    "- $L$: number of `Land` observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75315540-4081-4bd2-b976-a792bd7361d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"202pt\" height=\"107pt\"\n",
       " viewBox=\"0.00 0.00 202.25 107.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 103)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-103 198.25,-103 198.25,4 -4,4\"/>\n",
       "<!-- p -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>p</title>\n",
       "<ellipse fill=\"none\" stroke=\"red\" cx=\"27\" cy=\"-80\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-74.95\" font-family=\"Times,serif\" font-size=\"14.00\">p</text>\n",
       "</g>\n",
       "<!-- W -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>W</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"167.25\" cy=\"-81\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.25\" y=\"-75.95\" font-family=\"Times,serif\" font-size=\"14.00\">W</text>\n",
       "</g>\n",
       "<!-- p&#45;&gt;W -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>p&#45;&gt;W</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.33,-80.19C75.37,-80.34 105.14,-80.56 128.69,-80.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.48,-84.23 138.51,-80.8 128.53,-77.23 128.48,-84.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.12\" y=\"-83.88\" font-family=\"Times,serif\" font-size=\"14.00\">influence</text>\n",
       "</g>\n",
       "<!-- L -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>L</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"167.25\" cy=\"-20\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"167.25\" y=\"-14.95\" font-family=\"Times,serif\" font-size=\"14.00\">L</text>\n",
       "</g>\n",
       "<!-- p&#45;&gt;L -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>p&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.21,-70.36C72.79,-60.56 108,-45.28 133.72,-34.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.92,-37.41 142.7,-30.22 132.14,-30.99 134.92,-37.41\"/>\n",
       "</g>\n",
       "<!-- N -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>N</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">N</text>\n",
       "</g>\n",
       "<!-- N&#45;&gt;W -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>N&#45;&gt;W</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M49.91,-27.98C72.56,-38.3 108.17,-54.53 134.03,-66.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.52,-69.47 143.07,-70.44 135.42,-63.1 132.52,-69.47\"/>\n",
       "</g>\n",
       "<!-- N&#45;&gt;L -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>N&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.33,-18.38C75.37,-18.69 105.14,-19.12 128.69,-19.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.46,-22.95 138.51,-19.6 128.56,-15.95 128.46,-22.95\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x3035041d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.draw_causal_graph(\n",
    "    edge_list=[\n",
    "        (\"p\", \"W\"),\n",
    "        (\"p\", \"L\"),\n",
    "        (\"N\", \"L\"),\n",
    "        (\"N\", \"W\")\n",
    "    ],\n",
    "    graph_direction=\"LR\",\n",
    "    node_props={\n",
    "        \"p\": {\"color\": \"red\"}\n",
    "    },\n",
    "    edge_props={\n",
    "        (\"p\", \"W\"): {\"label\": \"influence\"}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f3287",
   "metadata": {},
   "source": [
    "- This graph defines a causal model, of how $p, N$ effect the values of $W, L$. This is the same as saying it defines some function $f$ that maps $p, N$ onto the values of $W, L$, i.e.  $W, L = f(p, N)$\n",
    "- Scientific knowledge defines what $f$ is or can be\n",
    "\n",
    "The unglamourous basis of applied probability:\n",
    "> **Things that can happen more ways are more plausible.**\n",
    "\n",
    "\n",
    "#### Bayesian data analysis\n",
    "\"Very simple, very humble\"\n",
    "- For each possible explanation of the sample\n",
    "- Count all the ways the sample could occur\n",
    "- **The explanations with the largest number of ways to produce the observed sample are more plausible**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c5bc9",
   "metadata": {},
   "source": [
    "## 3. Design a statistical procedure to produce an estimate\n",
    "### Garden of Forking Data\n",
    "Following the mantra above...\n",
    "\n",
    "- for each possible **proportion of water**, $p$\n",
    "- count all the ways the sample of tosses could have occurred\n",
    "- the $p$ that are associated with more ways to produce the sample are more plausible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38525410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 'WLW'\n",
      "(1) LLLL p(W) = 0.0\t\t0 Ways to Produce\n",
      "(2) WLLL p(W) = 0.25\t\t3 Ways to Produce\n",
      "(3) WWLL p(W) = 0.5\t\t8 Ways to Produce\n",
      "(4) WWWL p(W) = 0.75\t\t9 Ways to Produce\n",
      "(5) WWWW p(W) = 1.0\t\t0 Ways to Produce\n"
     ]
    }
   ],
   "source": [
    "def calculate_n_ways_possible(observations: str, n_water: int, resolution: int = 4):\n",
    "    \"\"\"\n",
    "    Calculate the number of ways to observing water ('W') given the toss of a globe\n",
    "    with `resolution` number of sides and `n_water` faces.\n",
    "    \n",
    "    Note: this method results in numerical precision issues (due to the product) when the\n",
    "    resolution of 16 or so, depending on your system.\n",
    "    \"\"\"\n",
    "    assert n_water <= resolution\n",
    "    \n",
    "    # Convert observation string to an array\n",
    "    observations = np.array(list(observations.upper()))\n",
    "    \n",
    "    # Create n-sided globe with possible outcomes\n",
    "    possible = np.array(list(\"L\" * (resolution - n_water)) + list(\"W\" * n_water))\n",
    "    \n",
    "    # Tally up ways to obtain each observation given the possible outcomes\n",
    "    # Here we use brute-force, but we could also use the analytical solution below\n",
    "    ways = []\n",
    "    for obs in observations:\n",
    "        ways.append((possible == obs).sum())\n",
    "    \n",
    "    p_water = n_water / resolution\n",
    "    # perform product in log space for numerical precision\n",
    "    n_ways = np.round(np.exp(np.sum(np.log(ways)))).astype(int)\n",
    "    return n_ways, p_water\n",
    "\n",
    "\n",
    "def run_globe_tossing_simulation(observations, resolution, current_n_possible_ways=None):\n",
    "    \"\"\"Simulate the number of ways you can observe water ('W') for a globe of `resolution`\n",
    "    sides, varying the proportion of the globe that is covered by water.\n",
    "    \"\"\"\n",
    "    # For Bayesian updates\n",
    "    current_n_possible_ways = current_n_possible_ways if current_n_possible_ways is not None else np.array([])\n",
    "    \n",
    "    print(f\"Observations: '{observations}'\")\n",
    "    p_water = np.array([])\n",
    "    for n_W in range(0, resolution + 1):\n",
    "        n_L = resolution - n_W\n",
    "        globe_sides = \"W\" * n_W + \"L\" * n_L\n",
    "        n_possible_ways, p_water_ = calculate_n_ways_possible(observations, n_water=n_W, resolution=resolution)\n",
    "        print(f\"({n_W+1}) {globe_sides} p(W) = {p_water_:1.2}\\t\\t{n_possible_ways} Ways to Produce\")\n",
    "\n",
    "        p_water = np.append(p_water, p_water_)\n",
    "        current_n_possible_ways = np.append(current_n_possible_ways, n_possible_ways)\n",
    "\n",
    "    return current_n_possible_ways, p_water\n",
    "\n",
    "\n",
    "RESOLUTION = 4\n",
    "observations = \"WLW\"\n",
    "n_possible_ways, p_water = run_globe_tossing_simulation(observations, resolution=RESOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fbb48f",
   "metadata": {},
   "source": [
    "## Bayesian (online) Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29063cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation_possible_ways, _ = run_globe_tossing_simulation(\"W\", resolution=RESOLUTION)\n",
    "\n",
    "# Online update\n",
    "n_possible_ways *= new_observation_possible_ways\n",
    "\n",
    "print(\"\\nUpdated Possibilities given new observation:\")\n",
    "for ii in range(0, RESOLUTION + 1):    \n",
    "    print(f\"({ii+1}) p(W) = {p_water[ii]:1.2}\\t\\t{int(n_possible_ways[ii])} Ways to Produce\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78d8f8",
   "metadata": {},
   "source": [
    "## The whole sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c70ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 4\n",
    "observations = \"WLWWWLWLW\"\n",
    "n_W = len(observations.replace(\"L\", \"\"))\n",
    "n_L = len(observations) - n_W\n",
    "\n",
    "n_possible_ways, p_water = run_globe_tossing_simulation(observations, resolution=RESOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f03414",
   "metadata": {},
   "source": [
    "show that we get identical answers with the analytical solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c4af49-1acf-459c-9585-52fbb09387b0",
   "metadata": {},
   "source": [
    "#### Results suggest the Analytical Solution $W,L = (Rp)^W \\times (R - Rp)^L$\n",
    "where $R$ is the number of possible globes, in this case 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d17c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_analytic_n_ways_possible(p, n_W, n_L, resolution=RESOLUTION):\n",
    "    \"\"\"This scales much better than the brute-force method\"\"\"\n",
    "    return (resolution * p) ** n_W * (resolution - resolution * p) ** n_L\n",
    "\n",
    "analytic_n_possible_ways = np.array([calculate_analytic_n_ways_possible(p, n_W, n_L) for p in p_water])\n",
    "assert (analytic_n_possible_ways == n_possible_ways).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25c2e82-9b21-42c6-b25f-67333dcea026",
   "metadata": {},
   "source": [
    "## Probability\n",
    "- non-negative values that sum to 1\n",
    "- normalizes large sums by the total counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27508218",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_probabilities = n_possible_ways / n_possible_ways.sum()\n",
    "\n",
    "print(\"Proportion\\tWays\\tProbability\")\n",
    "for p, n_w, n_p in zip(p_water, n_possible_ways, n_possible_probabilities):\n",
    "    print(f\"{p:1.12}\\t\\t{n_w:0.0f}\\t{n_p:1.2f}\")\n",
    "\n",
    "probs = np.linspace(0, 1, RESOLUTION+1)\n",
    "plt.subplots(figsize=(5, 5))\n",
    "plt.bar(x=probs, height=n_possible_probabilities, width= .9 / RESOLUTION, color='k')\n",
    "plt.xticks(probs);\n",
    "plt.ylabel(\"probability\")\n",
    "plt.xlabel(\"proportion water\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49953df1",
   "metadata": {},
   "source": [
    "## 4. Validate Statistical Procedure (3) using Generative Model (1)\n",
    "\n",
    "### Test Before You Est(imate) 🐤\n",
    "1. Code generative simulation (1)\n",
    "2. Code an estimator (3)\n",
    "3. Test (3) with (1); you should get expected output\n",
    "\n",
    "**IF YOU TEST NOTHING YOU MISS EVERYTHING**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae34bb3",
   "metadata": {},
   "source": [
    "### 4.1 Generative Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d9a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "np.random.seed(1)\n",
    "def simulate_globe_toss(p: float = 0.7, N: int = 9) -> list[str]:\n",
    "    \"\"\"Simulate N globe tosses with a specific/known proportion\n",
    "    p: float\n",
    "        The propotion of water\n",
    "    N: int\n",
    "        Number of globe tosses\n",
    "    \"\"\"\n",
    "    return np.random.choice(list(\"WL\"),  size=N, p=np.array([p, 1-p]), replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299b93f2-36ef-44e8-a8b9-2e3c42438b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(simulate_globe_toss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ed1b9-ce5d-4f07-9953-5495afb50a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint([simulate_globe_toss(p=1, N=11).tolist() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30937aff-7dae-454f-915e-d352478b2111",
   "metadata": {},
   "source": [
    "#### Test on Extreme settings\n",
    "With a large number of samples N, estimator should converge to known $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319f9e4-8e58-4510-928e-90bf73a4ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_p = 0.5\n",
    "\n",
    "simulated_ps = []\n",
    "sample_sizes = np.linspace(10, 100_000, 10)\n",
    "for N in sample_sizes:\n",
    "    simulated_p = np.sum(simulate_globe_toss(p=known_p, N=int(N)) == 'W') / N\n",
    "    simulated_ps.append(simulated_p)\n",
    "    \n",
    "plt.axhline(known_p, label=f\"Known p={known_p}\", color='k', linestyle='--')\n",
    "plt.legend();\n",
    "plt.plot(sample_sizes, simulated_ps);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7f8cd",
   "metadata": {},
   "source": [
    "### 4.2 Code the estimator\n",
    "\n",
    "The estimator takes in observations and returns a probability distribution (posterior) over potential estimates. Higher probability estimates should be more plausible given the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_posterior(observations, resolution=RESOLUTION, ax=None):\n",
    "    n_W = len(observations.replace(\"L\", \"\"))\n",
    "    n_L = len(observations) - n_W\n",
    "    \n",
    "    p_water = np.linspace(0, 1, resolution + 1)\n",
    "    n_possible_ways = np.array([calculate_analytic_n_ways_possible(p, n_W, n_L, resolution) for p in p_water])\n",
    "\n",
    "    posterior = n_possible_ways / n_possible_ways.sum()\n",
    "    potential_p = np.linspace(0, 1, resolution + 1)\n",
    "    \n",
    "    return posterior, potential_p\n",
    "\n",
    "def plot_posterior(observations, resolution=RESOLUTION, ax=None):\n",
    "    posterior, probs = compute_posterior(observations, resolution=resolution)\n",
    "    if ax is not None:\n",
    "        plt.sca(ax)\n",
    "    plt.bar(x=probs, height=posterior, width= .9 / resolution, color='k')\n",
    "    plt.xticks(probs[::2], rotation=45);\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.xlabel(\"proportion water\")\n",
    "    plt.title(f\"Posterior Calculated\\nfrom # Samples: {len(observations)}\")\n",
    "    \n",
    "plot_posterior(observations, resolution=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc89d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "known_p = .4\n",
    "simulated_observations = \"\".join(simulate_globe_toss(p=known_p, N=100))\n",
    "plot_posterior(simulated_observations, resolution=20)\n",
    "plt.axvline(known_p, color='C0', label='True Proportion')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85153d",
   "metadata": {},
   "source": [
    "## Infinite Possibilities\n",
    "\n",
    "### Moving from an N-sided globe to an infinitely-sided globe.\n",
    "As we increase resolution of globe\n",
    "- there are more bars/finer-grained resolution along the proportion axis\n",
    "- bars get shorter with more possibilities -- they must sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183724f-ba16-43d0-90c6-ec9e90f0ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "known_p = .7\n",
    "simulated_observations = \"\".join(simulate_globe_toss(p=known_p, N=30))\n",
    "_, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "for ii, possibilities in enumerate([5, 10, 20]):\n",
    "    plot_posterior(simulated_observations, resolution=possibilities, ax=axs[ii])\n",
    "    plt.ylim([-.05, 1])\n",
    "    axs[ii].set_title(f\"{possibilities} possibilities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86faad4-b59b-4255-b8ac-4d862ae4be7e",
   "metadata": {},
   "source": [
    "### Beta Distribution\n",
    "\n",
    "Analytical function that gives us the pdf as the limit as number of possibilities $\\rightarrow \\infty$\n",
    "\n",
    "$$\n",
    "p = \\frac{(W + L + 1)!}{W!L!} p^W(1-p)^L\n",
    "$$\n",
    "\n",
    "where $\\frac{(W + L + 1)!}{W!L!}$ is a normalizing constant to make the distribution sum to 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb58c96-f238-4066-b846-5645cf7632f2",
   "metadata": {},
   "source": [
    "### Tossing the Globe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87485419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "def beta_posterior(n_W: int, n_L: int, p: float) -> float:\n",
    "    \"\"\"Calculates the beta posterior over proportions `p` given a set of\n",
    "    `N_W` water and `N_L` land observations\n",
    "    \"\"\"\n",
    "    return factorial(n_W + n_L + 1) / (factorial(n_W) * factorial(n_L)) * p ** n_W * (1-p) ** n_L\n",
    "\n",
    "\n",
    "def plot_beta_posterior_from_observations(observations: str, resolution: int = 50, **plot_kwargs) -> None:\n",
    "    \"\"\"Calculates and plots the beta posterior for a string of observations\"\"\"\n",
    "    n_W = len(observations.replace(\"L\", \"\"))\n",
    "    n_L = len(observations) - n_W\n",
    "    proportions = np.linspace(0, 1, resolution)\n",
    "        \n",
    "    probs = beta_posterior(n_W, n_L, proportions)\n",
    "    plt.plot(proportions, probs, **plot_kwargs)\n",
    "    plt.yticks([])\n",
    "    plt.title(observations)\n",
    "    \n",
    "\n",
    "# Tossing the globe\n",
    "observations = \"WLWWWLWLW\"\n",
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "for ii in range(9):\n",
    "    ax = axs[ii // 3][ii % 3]\n",
    "    plt.sca(ax)\n",
    "    # Plot previous\n",
    "    if ii > 0:\n",
    "        plot_beta_posterior_from_observations(observations[:ii], color='k', linestyle='--')\n",
    "    else:\n",
    "        # First observation, no previous data\n",
    "        plot_beta_posterior_from_observations('', color='k', linestyle='--')\n",
    "        \n",
    "    color = 'C1' if observations[ii] == 'W' else 'C0'\n",
    "    plot_beta_posterior_from_observations(observations[:ii+1], color=color, linewidth=4, alpha=.5)\n",
    "    \n",
    "    if not ii % 3:\n",
    "        plt.ylabel(\"posterior probability\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee318f2-526e-4bf2-baa2-51e024210533",
   "metadata": {},
   "source": [
    "## On Bayesian Inference...\n",
    "- **There is no minimun sample size** -- fewer samples fall back to prior\n",
    "- **Posterior shape embodies the sample size** -- more data makes the posterior more precise\n",
    "- There is no point estimates -- **the estimate is the entire posterior distribution**\n",
    "- There is no true interval -- there are an infinite number of intervals one could draw, each is arbitrary and depends on what you're trying to communicate/summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bfa4ed-5fef-4065-9767-32a5cdd0f41e",
   "metadata": {},
   "source": [
    "## From Posterior to Prediction\n",
    "- To make predictions, we must average (i.e. integrate) over the entire posterior -- this averages over the uncertainty in the posterior\n",
    "- We could do this with integral calculus\n",
    "- OR, we could just **take samples from the posterior and average over those**\n",
    "\n",
    "**TURN A CALCULUS PROBLEM INTO A DATA SUMMARY PROBLEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac9be4",
   "metadata": {},
   "source": [
    "### Sampling from Posterior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d139e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 6, 3\n",
    "# draw random samples from Beta PDF\n",
    "beta_posterior_pdf = stats.beta(a, b)\n",
    "beta_posterior_samples = beta_posterior_pdf.rvs(size=1000)\n",
    "\n",
    "# Show that our beta postorior captures shape of beta-distributed samples\n",
    "plt.hist(beta_posterior_samples, bins=50, density=True, label='samples');\n",
    "probs = np.linspace(0, 1, 100)\n",
    "plt.plot(probs, beta_posterior(a-1, b-1, probs), linewidth=3, color='k', linestyle='--', label='beta distribution')\n",
    "plt.xlabel(\"proportion water\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984483a",
   "metadata": {},
   "source": [
    "### Sampling from Posterior Predictive Distribution\n",
    "**Posterior Prediction**: a prediction for out-of-sample data based on the current posterior estimate\n",
    "- 1. Draw a sample of model parameters from the posterior (i.e. proportions)\n",
    "- 2. Generate/simulate data predictions using our generative model and the sampled parameters\n",
    "- 3. The resulting probability distribution is our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04824e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sample parameters values from posterior\n",
    "N_posterior_samples = 10_000\n",
    "posterior_samples = beta_posterior_pdf.rvs(size=N_posterior_samples)\n",
    "\n",
    "# 2. Use samples for the posterior to simulate sampling 10 observations from our generative model\n",
    "N_draws_for_prediction = 10\n",
    "posterior_predictive = [(simulate_globe_toss(p, N_draws_for_prediction) == 'W').sum() for p in posterior_samples]\n",
    "ppd_unique, ppd_counts = np.unique(posterior_predictive, return_counts=True)\n",
    "\n",
    "# ...for comparison we can compare to the distribution that results from pinning the parameter to a specific value\n",
    "specific_prob = 0.64\n",
    "specific_predictive = [(simulate_globe_toss(specific_prob, N_draws_for_prediction) == 'W').sum() for _ in posterior_samples]\n",
    "specific_unique, specific_counts = np.unique(specific_predictive, return_counts=True)\n",
    "\n",
    "plt.bar(specific_unique, specific_counts, width=.5, color='k', label=f'simulation at p={specific_prob:1.2}');\n",
    "plt.bar(ppd_unique, ppd_counts, width=.2, color='C1', label='posterior predictive');\n",
    "plt.xlabel(\"$\\hat n_W$\")\n",
    "plt.ylabel('count')\n",
    "plt.title(f\"number of W samples predicted $\\hat n_W$ from {N_draws_for_prediction} globe flips\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b4748-3e97-43a7-b4a8-bc939adfc3b4",
   "metadata": {},
   "source": [
    "### Sampling is Handsom & Handy\n",
    "Things we'll compute via sampling\n",
    "- Forecasts\n",
    "- Causal effects\n",
    "- Counterfactuals\n",
    "- Prior Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e318c01",
   "metadata": {},
   "source": [
    "# Summary: Bayesian Data Analysis\n",
    "- For each possible explanation of data\n",
    "- Count all the ways that data could occur under that explanation\n",
    "- The explanations with more ways to produce data are more plausable\n",
    "\n",
    "## Bayesian Modesty\n",
    "- If your generative model is correct, you can't do better: this will be an optimal solution\n",
    "- Gives no gaurantees, only provides what you put into it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a92cb",
   "metadata": {},
   "source": [
    "# Bonus: Misclassification\n",
    "In previous examples, we  do not consider sampling error or noise in measurement. In other words the number of `Water` observations that we measure may not be the _true_ value.\n",
    "\n",
    "This means that the _true_ value for $W$ is unknown / unmeasured, but we instead measure $W^*$ that is caused by both the true, unmeasured $W$ and the measurement process $M$. If we know our measurement error rate, we can attempt to model it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1ed0-b31c-41c5-8b89-43e516be641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.draw_causal_graph(\n",
    "    edge_list=[\n",
    "        (\"p\", \"W\"),\n",
    "        (\"W\", \"W*\"),\n",
    "        (\"M\", \"W*\"),\n",
    "        (\"N\", \"W\")\n",
    "    ],\n",
    "    node_props={\n",
    "        \"p\": {\"color\": \"red\", \"style\": \"dashed\"},\n",
    "        \"W\": {\"style\": \"dashed\", \"label\": \"actual W\"},\n",
    "        \"W*\": {\"label\": \"noisy W, W*\"},\n",
    "        \"unobserved\": {\"style\": \"dashed\"},\n",
    "        \"M\": {\"label\": \"measurement error, M\"}\n",
    "    },\n",
    "    graph_direction=\"LR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c47ad8",
   "metadata": {},
   "source": [
    "## Missclassification Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0149a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_noisy_globe_toss(p: float=0.7, N: int=9, error_rate: float=0.1) -> np.ndarray:\n",
    "    # True sample\n",
    "    sample = np.random.choice(list(\"WL\"),  size=N, p=np.array([p, 1-p]), replace=True)\n",
    "    \n",
    "    # Error-induced sample\n",
    "    error_trials = np.random.rand(N) < error_rate\n",
    "    errors_effect_sample_trials = (sample == 'W') & error_trials\n",
    "    sample[errors_effect_sample_trials] = 'L'\n",
    "    return sample\n",
    "\n",
    "simulate_noisy_globe_toss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6aec7b-7418-4cd9-8595-3723b1730462",
   "metadata": {},
   "source": [
    "## Missclassification Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unnormalized_n_ways_possible_with_error(p: float, n_W: int, n_L: int, error_rate: float=0.1) -> float:\n",
    "    n_W_error = (p * (1 - error_rate) + ((1 - p) * error_rate)) ** n_W \n",
    "    n_L_error = ((1 - p) * (1 - error_rate) + (p * error_rate)) ** n_L\n",
    "    return n_W_error * n_L_error\n",
    "\n",
    "a, b = 6, 3\n",
    "resolution = 100\n",
    "proportions = np.linspace(0, 1, resolution)\n",
    "error_rate = 0.1\n",
    "error_posterior = np.array(\n",
    "    [\n",
    "        calculate_unnormalized_n_ways_possible_with_error(p, a, b, error_rate) for p in proportions\n",
    "    ]\n",
    ")\n",
    "beta_posterior_values = beta_posterior(a, b, proportions)\n",
    "\n",
    "# Infer normalization constant Z directly from samples\n",
    "error_posterior *= resolution / error_posterior.sum()\n",
    "beta_posterior_values *= resolution / beta_posterior_values.sum()\n",
    "\n",
    "plt.subplots(figsize=(6, 6))\n",
    "plt.plot(proportions, beta_posterior_values, label='previous posterior', color='k', linewidth=4)\n",
    "plt.plot(proportions, error_posterior, label=f'misclassification posterior\\n(error rate={error_rate:1.2})', linewidth=4)\n",
    "plt.xlabel(\"proportion of water\")\n",
    "plt.ylabel(\"posterior probability\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2837d6",
   "metadata": {},
   "source": [
    "## Measurement Matters\n",
    "- better to model measurement error than to ignore it\n",
    "- same goes for mssing data\n",
    "- what matters is _why_ samples differ, and that we are explicit about how model it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
